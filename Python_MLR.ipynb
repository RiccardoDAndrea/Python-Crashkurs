{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Empirisches Projekt\n",
    "---\n",
    "### **Skript zu Daten Manipulation, Visulallisierung und zur Regressions Analyse**\n",
    "\n",
    "Dieses Sktipt soll euch helfen eine Datenanalyse sowie eine Simple oder eine Mutiple Regression aufzubauen.\n",
    "-> Falls ihr fragen habt bitte sagt mir bescheid ich helfe gerne aus!\n",
    "\n",
    "> E-Mail: riccardo.dandrea@live.de\n",
    "> Ihr könnte gerne eine Mail schreiben wo wir uns Per zoom treffen können, falls ihr schwierigkeiten habt bei der Programmierung:\n",
    "> BITTE schreibt in der MAIL:\n",
    "> - Was habt ihr vor ?\n",
    "> - Wo liegt das Problem mit Code und Fehlermeldung\n",
    "> - und wann ihr euch Per zoom treffen wollt Tag und Uhrzeit.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Für die Datenanalyse kann als unterstützung der Leitfaden \"Leitfaden.ipynbn\" als unterstützung genutzt werden.\n",
    "Ab Punkt 2. wird erklärt wie Libaries installiert werden und wie die Daten eingelesen werden können. Sowie weitere Schritte zur Datenanalyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab:\n",
    "---\n",
    "##### 1. [Python Programmierung mit Google Colab link](https://colab.research.google.com/drive/1KXsA9WTFS9AxezEEaI3gYirv42b5-0rb#scrollTo=VJul2ijN-eHj)\n",
    "\n",
    "<img src=\"Pictures_for_Explanation/1_Google_Colab_Starten.png\" alt=\"Bildbeschreibung\" width=\"700\"/>\n",
    "\n",
    "\n",
    "\n",
    "##### 2. Um ein Skript zu öffnen Navigiert auf Datei was oben Rechts vorzufinden ist und klickt \"Notebook öffnen\"\n",
    "\n",
    "<img src=\"Pictures_for_Explanation/2_Datei_Optionen_öffnen.png\" alt=\"Bildbeschreibung\" width=\"700\"/>\n",
    "\n",
    "##### 3. Danach geht ihr  auf Github und fügt folgenden Link hinzu https://github.com/RiccardoDAndrea/Python-Crashkurs\n",
    "\n",
    "<img src=\"Pictures_for_Explanation/3_Zuletzt_Geöffnet.png\" alt=\"Bildbeschreibung\" width=\"700\"/>\n",
    "\n",
    "##### 4. Nachdem Laden werdet ihr mehere Datein wie Skripte vorfinden.\n",
    "<img src=\"Pictures_for_Explanation/4_Github_URL_eingeben.png\" alt=\"Bildbeschreibung\" width=\"700\"/>\n",
    "\n",
    "##### 5. Für die Mutiple Lineare Regression wählt ihr Python_MLR.ipynb und somit habt ihr erfolgreich das Skript zur bearbeitung eingeladen\n",
    "<img src=\"Pictures_for_Explanation/5_Python_MLR.png\" alt=\"Bildbeschreibung\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordner Data ist bereits vorhanden\n",
      "Ordner Data ist bereits vorhanden\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"Data\"):\n",
    "    print(\"Ordner Data erstellt\")\n",
    "    os.makedirs(\"Data\") \n",
    "elif os.path.exists(\"Data\"):\n",
    "    print(\"Ordner Data ist bereits vorhanden\")\n",
    "\n",
    "\n",
    "if not os.path.exists(\"MLR_Output\"):\n",
    "    print(\"Ordner Data erstellt\")\n",
    "    os.makedirs(\"MLR_Output\") \n",
    "elif os.path.exists(\"MLR_Output\"):\n",
    "    print(\"Ordner Data ist bereits vorhanden\")\n",
    "\n",
    "# Erstellt dir ein Ordner wo du deine Daten speichern kannst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Füge hier alle benötigten Libaries ein:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'scipy' ist bereits installiert.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_and_import(package):\n",
    "    try:\n",
    "        # Überprüfen, ob das Paket bereits installiert ist\n",
    "        importlib.import_module(package)\n",
    "        print(f\"'{package}' ist bereits installiert.\")\n",
    "    except ImportError:\n",
    "        # Falls das Paket nicht installiert ist, wird es installiert\n",
    "        print(f\"'{package}' wird installiert.\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "\n",
    "install_and_import('scipy')  # Ersetzt 'numpy' mit dem gewünschten Paketnamen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuelle Installation \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lese hier deine Daten ein:\n",
    "---\n",
    "\n",
    "gebe dazu in den \"`Path to your file\"` wo deine Datei liegt, sowie den passenden Seprator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer= \"https://raw.githubusercontent.com/RiccardoDAndrea/Python-Crashkurs/refs/heads/main/Data/wage.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>metro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.07</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.12</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.54</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.68</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.09</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage  educ  exper  metro\n",
       "0  2.07    12      7      1\n",
       "1  2.12    12     35      1\n",
       "2  2.54    16     20      1\n",
       "3  2.68    12     24      1\n",
       "4  3.09    13      4      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/wage_csv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData/wage_csv.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Desktop/Github/Python-Crashkurs/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Github/Python-Crashkurs/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/Github/Python-Crashkurs/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Github/Python-Crashkurs/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/Github/Python-Crashkurs/venv/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/wage_csv.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filepath_or_buffer= \"Data/wage_csv.csv\", \n",
    "                 sep=',')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begutachte deine Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gebe dir die ersten 5 reihen des Datensatzes aus:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reihen, Spalten = df.shape\n",
    "\n",
    "# gebe die Anzahl der Reihen und Spalten aus:\n",
    "print(\"Anzahl der Reihen: \", Reihen)\n",
    "print(\"Anzahl der Spalten: \", Spalten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anpassung der Datentypen\n",
    "---\n",
    "Bevor Daten richtig Manipuliert werden können ist es von wichtigkeit die Datentypen anzupassen.\n",
    "Welche Datentypen es gibt kannst du im Detail im Leitfaden nachlesen unter Punkt 1.3.\n",
    "\n",
    "Folgende Datentypen gibt es:\n",
    "\n",
    "-> `\"string\"`\n",
    "\n",
    "-> `\"int\"`\n",
    "\n",
    "-> `\"float\"`\n",
    "\n",
    "-> `\"bool\"`\n",
    "\n",
    "-> `\"category\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können auch *Datentypen* von Spalten ändern, um die Analyse zu erleichtern.\n",
    "\n",
    "- *Datentypen* sind wichtig für die Analyse, da sie bestimmen, welche Operationen auf den Daten durchgeführt werden können.\n",
    "\n",
    "Wenn wir ein `String` statt ein `int` haben können wir keine Rechen Operationen durchführen. \n",
    "Wie Mittelwert, Median, Standardabweichung, Varianz, etc.\n",
    "\n",
    "- Daher ist es wichtig die *Datentypen* zu kennen und zu ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['metro'] = df['metro'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Code wirst du eine Statitische Zusammenfassung des Datensatzes erhalten.\n",
    "Nimm dir eigene Minuten Zeit dein Daten satz zu analysieren und die wichtigsten Informationen herauszufinden.\n",
    "\n",
    "- Hinterfrage deine Daten und versuche Zusammenhänge zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe().round(2))\n",
    "\n",
    "\n",
    "# save output of the describtion as a text file\n",
    "with open('MLR_Output/Summary statistics.txt', 'w') as f:\n",
    "    f.write(df.describe().round(2).to_string()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umgang mit NaN-Werten (Not a Number):\n",
    "---\n",
    "NaN Werte sind Daten die nicht richtig erhoben worden oder auch fehler enthalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim Umgang mit fehlenden Werten in der Spalte \"educ\" (Bildungsjahre) sollte eine besonders sorgfältige Vorgehensweise angewendet werden.\n",
    "\n",
    "**Frage: Kann man fehlende Werte in der Spalte \"educ\" sinnvoll ersetzen?**\n",
    "\n",
    "Antwort: *Ja, aber mit Vorsicht.* \n",
    "Die Anzahl der Bildungsjahre kann möglicherweise durch den `Durchschnitt`, `Median` oder `Modus` ersetzt werden, aber dies muss mit Bedacht erfolgen. Der Grund ist, dass Bildung ein stark individueller Faktor ist und eine pauschale Ersetzung (z.B. mit dem `Mittelwert`) die Daten verfälschen könnte.\n",
    "Wenn fehlende Werte in `\"educ\"` durch den Durchschnitt oder eine andere aggregierte Statistik ersetzt werden, kann dies dazu führen, dass wichtige individuelle Unterschiede verwischt werden. Das könnte letztlich das Modell in die Irre führen, da die Annahmen über die Bildungsjahre nicht korrekt widergespiegelt werden. Eine solche Verzerrung könnte die Ergebnisse von Modellen wie der Regressionsanalyse oder anderen maschinellen Lernverfahren erheblich beeinflussen und zu ungenauen Vorhersagen führen.\n",
    "\n",
    "Statt pauschaler Ersetzungen sollten im besten Fall Strategien wie:\n",
    "\n",
    "- Datenquellen ergänzen, um fehlende Werte zu rekonstruieren,\n",
    "- Imputation mit verwandten Variablen (z.B. Alter, Berufserfahrung), oder\n",
    "- Löschen betroffener Zeilen, wenn der Anteil fehlender Werte gering ist,\n",
    "in Betracht gezogen werden, um die Verzerrung minimal zu halten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entferne Zeilen mit fehlenden Werten (NaN)\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# Fülle NaN-Werte mit dem Durchschnitt jeder Spalte\n",
    "#df = df.fillna(df.mean())\n",
    "\n",
    "\n",
    "# Alternativ: Fülle NaN-Werte einer bestimmten Spalte (z.B. 'Wage') mit deren Durchschnitt\n",
    "df['wage'] = df['wage'].fillna(df['wage'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filterung der Daten\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Datenfilterung kannst du neue Einsichten für deine Daten erhalten.\n",
    "Diese können wiederum in einer neuen `Variable` eingespeichert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df`: Der DataFrame, der die ursprünglichen Daten enthält.\n",
    "\n",
    "- `df[\"wage\"] > 12.00`: Die Filterbedingung. Es wird überprüft, ob der Wert in der Spalte \"wage\" größer als 12.00 ist.\n",
    "\n",
    "- `df[df[\"wage\"] > 12.00]`: Das Ergebnis ist ein neuer DataFrame (df_filtered), der nur die Zeilen enthält, in denen der Wert in der Spalte \"wage\" größer als 12.00 ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df[\"wage\"] > 12]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Filterung mit mehreren Konditionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_educ = df[(df[\"wage\"] > 12)  &  # Beachte das du nun deine gewünschte Spalten namen hinzufügen musst\n",
    "                      (df[\"educ\"] == 12) & \n",
    "                      (df[\"metro\"] == 0) &\n",
    "                      (df[\"exper\"] > 1)] \n",
    "\n",
    "df_filtered_educ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisierungen:\n",
    "---\n",
    "\n",
    "Visualisierungen sind leicht zu erstellen und bieten oft wertvolle Einblicke in die Daten, die möglicherweise anders ausfallen, als zunächst erwartet.\n",
    "\n",
    "Sie sind besonders wichtig, da sie nicht nur helfen, die Ergebnisse des Regressionsmodells besser zu verstehen, sondern auch dazu beitragen können, die Vorhersagen anschaulich zu untermauern. Wie genau Visualisierungen die Aussagekraft der Modellierung unterstützen, werden wir nach der Durchführung und dem Testen der Regression näher betrachten.\n",
    "\n",
    "\n",
    "Für die Visualisierung nutzen wir `Seaborn`, für die Beschriftungen nutzen wir `Matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korrelations Matrix\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Im folgenden erstellen wir eine Korrelations Matrix.\n",
    "Wir verwenden die Daten um diese zu Visualisieren in einer Heatmap.\n",
    "\n",
    "- `df.corr()` initialisiert die Korrelations Matrix.\n",
    "- `method = \"pearson\"` bestimmt welcher Methode die berechnungen durch geführt werden sollen. Folgenden Methoden sind möglich: `pearson, kendall, spearman`\n",
    "- `nummeric_only = True` berechnet nur die Korrelation von nummerischen werte wie Int oder Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method = \"pearson\", numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem wir eine Korrelationsmatrix erstellt haben, können wir diese in einer Heatmap visualisieren.\n",
    "\n",
    "- `sns.heatmap()` erstellt eine Heatmap\n",
    "- `df.corr(method = \"pearson\", numeric_only=True)` gibt die Korrelationsmatrix zurück\n",
    "- `annot = True` zeigt die Werte in der Heatmap an\n",
    "\n",
    "- `plt.savefig(\"Vis/Title_\")` speichert unsere Heatmap in den Ordner `Vis` mit dem Namen `Title_` als Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data = df.corr(method = \"pearson\", numeric_only=True), \n",
    "            annot=True) \n",
    "plt.title(\"Heatmap der Korrelationen\")\n",
    "plt.show()\n",
    "plt.savefig(\"MLR_Output/Title_.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot\n",
    "---\n",
    "Der Code bleibt größtenteils gleich:\n",
    "\n",
    "- `sns.barplot()` initialisiert ein Balkendiagramm\n",
    "    - `data = df` Die Visualisierung werden die Datena aus der Variable df entommen \n",
    "    - `x = \"wage\"` nimmt die Daten aus dem DataFrame und wählt die Spalte \"wage\" aus\n",
    "    - `hue = \"metro\"` gruppierung der Daten in unseren Fall nach Metro\n",
    "    - `gap = 0.5` erstellt eine Lücke zwischen beide Boxplots\n",
    "- `plt.title(\"Boxplot von Erfahrung und Lohn\")`\n",
    "- `plt.grid(True)` fügt Gitterlinien hinzu\n",
    "- `plt.savefig(\"MLR_Output/Title_\")` speicher die Visualisierung in den Ordner Vis mit dem Titel: Title_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = df, x = \"wage\", hue = \"metro\", gap = 0.5)\n",
    "plt.title(\"Boxplot von Erfahrung und Lohn\")\n",
    "plt.ylabel(\"Lohn\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"MLR_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein Scatterplot zu erstellen, wird folgende Funktion verwendet\n",
    "- `sns.scatterplot()` initiiert ein Scatterplot mit folgenden Parameter:\n",
    "    - `data = df`                         # der Scatterplot verwendet die Daten von dein Variable `df`\n",
    "    - `x = \"exper\"`                       # Die X-Achse nutz die Daten auf dem Dataframe `exper`\n",
    "    - `y = \"wage\"`                        # Die Y-Achse nutz die Daten auf dem Dataframe `wage`\n",
    "    - `alpha = 0.5` # fügt eine Transparenz hinzu die uns hilft konzentrierte Stellen zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"exper\", y=\"wage\", alpha = 0.5) # alpha fügt transparenz hinzu\n",
    "plt.xlabel(\"Erfahrung\")\n",
    "plt.ylabel(\"Lohn\")\n",
    "plt.title(\"Scatterplot von Erfahrung und Lohn\")\n",
    "plt.savefig(\"MLR_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balkendiagramm\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x=\"metro\", y=\"wage\")\n",
    "plt.xlabel(\"Metro\")\n",
    "plt.ylabel(\"Lohn\")\n",
    "plt.title(\"Metro und Lohn\")\n",
    "plt.savefig(\"MLR_Output/Title_\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramm\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erklärung des Codes:\n",
    "\n",
    "1. Wir erstellen den Graphen durch `sns.histplot()`\n",
    "    \n",
    "    Parameter: \n",
    "    - `data = df[\"wage\"]` wir geben den Parameter die Spalte `\"wage\"` mit um den Histogramm mit Daten zufüllen\n",
    "    - `bins=30`  erwartet ein integer in wie viele Gruppen `\"wage\"` unterteilt werden sollen\n",
    "    \n",
    "2. Durch Matplotlib fügen wir die Achsenbeschriftung hinzu.\n",
    "    - `plt.xlabel(\"Lohn\")` gibt der X-Achse die beschriftung \"Lohn\"\n",
    "    - `plt.ylabel(\"Anzahl\")` gibt der Y-Achse die beschriftung \"Anzahl\"\n",
    "    - `plt.title(\"Histogramm des Lohns\")` gibt den Graphen den Titel \"Histogramm des Lohns\"\n",
    "    - `plt.title(\"Histogramm des Lohns\")\n",
    "    - `plt.xticks(np.arange(0, 70, step=10))` verändert die Skalierung der X-Achse indem wir sagen `np.arange(0,70, step = 10)`. Das heißt der niedrigste Wert ist 0 der höchste 70 auf der X-Achse in 10 Schritte wiedergeben\n",
    "    \n",
    "    - `plt.yticks(np.arange(0, 260, step=50))` verändert die Skalierung der Y-Achse indem wir sagen `np.arange(0,260, step = 50)`. Das heißt der niedrigste Wert ist 0 der höchste Wert ist 260 auf der Y-Achse in 50 Schritte wiedergeben\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"wage\", bins=30)\n",
    "plt.xlabel(\"Lohn\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.title(\"Histogramm des Lohns\")\n",
    "plt.xticks(np.arange(0, 70, step=5))\n",
    "plt.yticks(np.arange(0, 260, step=50))\n",
    "plt.savefig(\"MLR_Output/Title_\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne die Perzentile (25., 50., 75.)\n",
    "q25_wage = np.percentile(df['wage'], 25)\n",
    "q50_wage = np.percentile(df['wage'], 50)  # Median\n",
    "q75_wage = np.percentile(df['wage'], 75)\n",
    "\n",
    "# Plot der Verteilung\n",
    "sns.histplot(df['wage'], bins=30)\n",
    "\n",
    "# Füge die vertikalen Linien für die Perzentile hinzu\n",
    "plt.axvline(x=q25_wage, color='red', linestyle='--', label='25. Perzentil')\n",
    "plt.axvline(x=q50_wage, color='green', linestyle='--', label='50. Perzentil (Median)')\n",
    "plt.axvline(x=q75_wage, color='blue', linestyle='--', label='75. Perzentil')\n",
    "\n",
    "# Plot-Details\n",
    "plt.legend()\n",
    "plt.xlabel(\"Lohn\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.title(\"Histogramm des Lohns\")\n",
    "plt.savefig(\"MLR_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot\n",
    "---\n",
    "Erstellt ein Visualisierung zwischen den Beziehungen der Daten\n",
    "\n",
    "`sns.pairplot(df)`\n",
    "- `hue = \"metro\"` gruppiert die Daten nach Metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue = \"metro\")\n",
    "plt.savefig(\"MLR_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Lineare Regression Visualisieren\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data = df, x=\"educ\", y =\"wage\")\n",
    "plt.savefig(\"MLR_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data = df, x=\"exper\", y =\"wage\", scatter_kws={'color': 'grey'}, line_kws={'color': 'red'})\n",
    "plt.savefig(\"MLR_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data = df, x=\"metro\", y =\"wage\", scatter_kws={'color': 'grey'}, line_kws={'color': 'red'})\n",
    "\n",
    "plt.savefig(\"MLR_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressions Analyse\n",
    "---\n",
    "Im folgenden erstellen wir nun eine Mutiple Lineare Regression\n",
    "\n",
    "#### Formel:\n",
    "`wage ~ educ + exper + metro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols \n",
    "import sklearn as sk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lege deine abhängige und unabhängige Variable fest\n",
    "\n",
    "- In der `Variable X` erstellen wir ein neues Dataframe nur mit den Spalten educ, exper, metro (abhängige Variable)\n",
    "\n",
    "- In der `Variable Y` erstellen wir ein neues Dataframe nur mit den Spalte wage die wir demenstsprechend auch vorhersagen möchten (unabhängige Variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"educ\", \"exper\", \"metro\"]] \n",
    "y = df[\"wage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellung der Regression:\n",
    "Regressionen können auf viele wege erstellt werden wir arbeiten nun mit dem Package `Statsmodels` da diese viele Metriken uns wiedergeben mit weniger Code\n",
    "\n",
    "1. Möglichkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = sm.OLS(y, X)\n",
    "model = model_stats.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())\n",
    "\n",
    "with open('MLR_Output/Regression_summary.txt', 'w') as fh:\n",
    "    fh.write(model.summary().as_text()) # Speicher dein Regressions Ergebnis in einer Text Datei in dem Odner Regression Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formel: y_hat = intercept + b1 * educ + b1 * exper + b1 * educ + b1 * metro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Möglicheit die mehr an R erinnert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('wage ~ educ + exper + metro', \n",
    "                   data=df).fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# with open('MLP_Output/Regression_summary.txt', 'w') as fh:\n",
    "#     fh.write(model.summary().as_text()) # Speicher dein Regressions Ergebnis in einer Text Datei in dem Odner Regression Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfidenz Intervalle:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_intervals = model.conf_int(alpha=0.05, cols=None).round(3) # 95% Konfidenzintervalle\n",
    "conf_intervals.columns = ['0.5 %', '99.5 %']  # Umbenennen der Spalten\n",
    "conf_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersagen treffen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X)\n",
    "\n",
    "# Die ersten 5 Vohersagen, um alle zu sehen entferne die [:5]\n",
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Intercept = model.params[0]\n",
    "educ_1 = model.params[1]\n",
    "exper_2 = model.params[2]\n",
    "metro_3 = model.params[3]\n",
    "\n",
    "print(\"Intercept: \", Intercept)\n",
    "print(\"educ: \", educ_1)\n",
    "print(\"exper: \", exper_2)\n",
    "print(\"metro: \", metro_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressionsformel als String formatieren\n",
    "formula = f'wage = {Intercept:.3f} + {educ_1:.3f}*educ + {exper_2:.3f}*exper + {metro_3:.3f}*metro'\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educ = 12\n",
    "exper = 12\n",
    "metro = 1\n",
    "\n",
    "result = Intercept + educ_1 * educ + exper_2 * exper + metro_3 * metro\n",
    "print(\"Das Vorhergesagte Einkommen: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot erstellen (Farben und Transparenz anpassen)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=prediction, y=y, alpha=0.6, color=\"blue\", edgecolor=\"w\", s=80)  # s=80 macht die Punkte größer\n",
    "\n",
    "# Plot-Titel und Achsenbeschriftungen\n",
    "plt.title(\"Tatsächliche Werte vs Vorhergesagte Werte\", fontsize=16)\n",
    "plt.xlabel(\"Tatsächliche Werte\", fontsize=14)\n",
    "plt.ylabel(\"Vorhergesagte Werte\", fontsize=14)\n",
    "\n",
    "# Die Regressionsformel in die Grafik einfügen\n",
    "plt.text(x=min(prediction), y=max(y), s=formula, fontsize=12, color='darkgreen', ha='left')\n",
    "\n",
    "# Plot anzeigen und speichern\n",
    "\n",
    "plt.savefig(\"MLR_Output/Title_Actual_vs_Predicted_with_formula.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot für educ gegen wage\n",
    "sns.scatterplot(x=df[\"educ\"], y=df[\"wage\"], alpha=0.5)\n",
    "\n",
    "# Regressionslinie hinzufügen\n",
    "sns.lineplot(x=df[\"educ\"], y=prediction, color='red')\n",
    "\n",
    "plt.title(\"Tatsächliche Werte vs Vorhergesagte Werte (mit Regressionslinie)\")\n",
    "plt.xlabel(\"Bildungsjahre (educ)\")\n",
    "plt.ylabel(\"Lohn (wage)\")\n",
    "\n",
    "plt.savefig(\"MLR_Output/educ_vs_wage_with_regression_line.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuale \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuale berechen\n",
    "Um Resiudale zu berechnen haben wir zwei möglichkeiten.\n",
    "\n",
    "1. Möglichkeit durch eine eingbaute Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model.resid\n",
    "residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Berechnung durchführen ohne eine Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_model = y - prediction # tatsächliche Werte - Vorhersagen\n",
    "residuals_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung der Residuale durch ein Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot der Vorhersagen gegen Residualen\n",
    "sns.scatterplot(x=prediction, y=residuals_model, alpha = 0.5)\n",
    "plt.title(\"Vorhersagen vs Residualen\")\n",
    "plt.axhline(y = 0, color = 'r', linestyle = '--') # fügt eine rote horziontale Linie hinzu\n",
    "plt.xlabel(\"Vorhersagen\")\n",
    "plt.ylabel(\"Residualen\")\n",
    "\n",
    "plt.savefig(\"MLR_Output/Title_Residuals_vs_Predictions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisierung der Residualen durch Residplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(x=prediction, y=residuals)\n",
    "plt.title(\"Residualen vs Vorhersagen\")\n",
    "plt.xlabel(\"Vorhersagen\")\n",
    "plt.ylabel(\"Residualen\")\n",
    "plt.savefig(\"MLR_Output/Title_\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung von Summe der quadrierten Residuen (SSR) \n",
    "SSResiduals = (residuals**2).sum()\n",
    "print(\"SSResiduals:\", SSResiduals)  \n",
    "\n",
    "# SST = Summe der quadrierten Abweichungen der abhängigen Variable vom Mittelwert \n",
    "SSTotal = ((y - y.mean())**2).sum()\n",
    "print(\"SSTotal:\", SSTotal)\n",
    "\n",
    "\n",
    "# # R-squared\n",
    "# R_squared = 1 - (SSResiduals/SSTotal)\n",
    "# print(\"R_squared:\", R_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(residuals, kde=True, bins=25)\n",
    "plt.title(\"Histogramm der Residualen\")\n",
    "plt.xlabel(\"Residualen\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.savefig(\"MLR_Output/Title_\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.qqplot(residuals, line='r')  # 'r' fügt die Referenzlinie hinzu\n",
    "plt.title(\"Q-Q Plot der Residuen\")\n",
    "plt.savefig(\"MLR_Output/Title_\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of variance (Anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# ANOVA-Test durchführen\n",
    "anova_results = anova_lm(model)  # Typ 2 ANOVA\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "anova_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heteroskedasticity testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.diagnostic import het_white\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_lm, bp_lm_pvalue, bp_fvalue, bp_f_pvalue = sm.stats.diagnostic.het_breuschpagan(\n",
    "    model.resid, model.model.exog)\n",
    "\n",
    "\n",
    "print(f\"LM Statistic: {bp_lm}\")\n",
    "print(f\"LM p-value: {bp_lm_pvalue}\")\n",
    "print(f\"F Statistic: {bp_fvalue}\")\n",
    "print(f\"F p-value: {bp_f_pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = sm.OLS(y, X).fit(cov_type=\"HC1\")\n",
    "print(ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multikollinearität\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# VIF Berechnung nur für die Variablen in X\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "\n",
    "# Berechne den VIF für jede unabhängige Variable\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation Multikollinearität: \n",
    "Analyse Multikollinearität:\n",
    "\n",
    "`const (40.34)`: Dieser Wert ist sehr hoch. Ein hoher VIF-Wert bei der Konstante (Intercept) ist jedoch nicht unbedingt problematisch, da die Konstante nicht direkt in der Modellinterpretation verwendet wird. Oftmals resultiert dies daraus, dass eine konstante Variable wie der Intercept perfekt mit sich selbst korreliert.\n",
    "\n",
    "`educ (1.04)`, `exper (1.03)`, `metro (1.01)`: Diese VIF-Werte sind sehr niedrig, nahe bei 1. Das bedeutet, dass es kaum Multikollinearität zwischen diesen unabhängigen Variablen gibt. Die Korrelation zwischen diesen Variablen ist minimal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial-Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_creamdf = pd.read_csv(\"https://raw.githubusercontent.com/RiccardoDAndrea/Python-Crashkurs/refs/heads/main/Data/Ice_cream_sales.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_creamdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_creamdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_creamdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_creamdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = ice_creamdf[\"Temperature (°C)\"].values.reshape(-1,1)\n",
    "X_log = sm.add_constant(X_poly)\n",
    "y_poly = ice_creamdf[\"Ice Cream Sales (units)\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "xp = polynomial_features.fit_transform(X_poly)\n",
    "xp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poly = sm.OLS(y_poly, xp).fit()\n",
    "ypred_poly = model_poly.predict(xp) \n",
    "\n",
    "ypred_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poly.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_poly,y_poly)\n",
    "plt.plot(X_poly,ypred_poly)\n",
    "\n",
    "plt.title(\"Polynomiale Regression\")\n",
    "plt.xlabel(\"Temperatur (°C)\")\n",
    "plt.ylabel(\"Eisverkäufe (Einheiten)\")\n",
    "plt.savefig(\"MLR_Output/Title_\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Log Model:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Beispiel-Daten\n",
    "data = {\n",
    "    'X': [1, 2, 3, 4, 5, 6],\n",
    "    'y': [1, 2, 4, 8, 16, 32]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Logarithmieren der Variablen\n",
    "df['log_X'] = np.log(df['X'])\n",
    "df['log_y'] = np.log(df['y'])\n",
    "\n",
    "# Hinzufügen einer Konstante für den Intercept\n",
    "X_log = sm.add_constant(df['log_X'])\n",
    "\n",
    "# Erstelle das log-log Modell\n",
    "model = sm.OLS(df['log_y'], X_log)\n",
    "results = model.fit()\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(results.summary())\n",
    "\n",
    "# Vorhersagen treffen\n",
    "y_pred_log = results.predict(X_log)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
