{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Empirisches Projekt\n",
    "---\n",
    "### **Skript zu Daten Manipulation, Visulallisierung und zur Regressions Analyse**\n",
    "\n",
    "Dieses Sktipt soll euch helfen eine Datenanalyse sowie eine Simple oder eine Mutiple Regression aufzubauen.\n",
    "-> Falls ihr fragen habt bitte sagt mir bescheid ich helfe gerne aus!\n",
    "\n",
    "> E-Mail: riccardo.dandrea@live.de\n",
    "> Ihr könnte gerne eine Mail schreiben wo wir uns Per zoom treffen können, falls ihr schwierigkeiten habt bei der Programmierung:\n",
    "> BITTE schreibt in der MAIL:\n",
    "> - Was habt ihr vor ?\n",
    "> - Wo liegt das Problem mit Code und Fehlermeldung\n",
    "> - und wann ihr euch Per zoom treffen wollt Tag und Uhrzeit.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Für die Datenanalyse kann als unterstützung der Leitfaden \"Leitfaden.ipynbn\" als unterstützung genutzt werden.\n",
    "Ab Punkt 2. wird erklärt wie Libaries installiert werden und wie die Daten eingelesen werden können. Sowie weitere Schritte zur Datenanalyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"Data\"):\n",
    "    print(\"Ordner Data erstellt\")\n",
    "    os.makedirs(\"Data\") \n",
    "elif os.path.exists(\"Data\"):\n",
    "    print(\"Ordner Data ist bereits vorhanden\")\n",
    "\n",
    "# Erstellt dir ein Ordner wo du deine Daten speichern kannst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Füge hier alle benötigten Libaries ein:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_and_import(package):\n",
    "    try:\n",
    "        # Überprüfen, ob das Paket bereits installiert ist\n",
    "        importlib.import_module(package)\n",
    "        print(f\"'{package}' ist bereits installiert.\")\n",
    "    except ImportError:\n",
    "        # Falls das Paket nicht installiert ist, wird es installiert\n",
    "        print(f\"'{package}' wird installiert.\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "\n",
    "install_and_import('scipy')  # Ersetzt 'numpy' mit dem gewünschten Paketnamen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuelle Installation \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lese hier deine Daten ein:\n",
    "---\n",
    "\n",
    "gebe dazu in den \"`Path to your file\"` wo deine Datei liegt, sowie den passenden Seprator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer= \"Data/wage.csv\", \n",
    "                 sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begutachte deine Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gebe dir die ersten 5 reihen des Datensatzes aus:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reihen, Spalten = df.shape\n",
    "\n",
    "# gebe die Anzahl der Reihen und Spalten aus:\n",
    "print(\"Anzahl der Reihen: \", Reihen)\n",
    "print(\"Anzahl der Spalten: \", Spalten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anpassung der Datentypen\n",
    "---\n",
    "Bevor Daten richtig Manipuliert werden können ist es von wichtigkeit die Datentypen anzupassen.\n",
    "Welche Datentypen es gibt kannst du im Detail im Leitfaden nachlesen unter Punkt 1.3.\n",
    "\n",
    "Folgende Datentypen gibt es:\n",
    "\n",
    "-> `\"string\"`\n",
    "\n",
    "-> `\"int\"`\n",
    "\n",
    "-> `\"float\"`\n",
    "\n",
    "-> `\"bool\"`\n",
    "\n",
    "-> `\"category\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können auch *Datentypen* von Spalten ändern, um die Analyse zu erleichtern.\n",
    "\n",
    "- *Datentypen* sind wichtig für die Analyse, da sie bestimmen, welche Operationen auf den Daten durchgeführt werden können.\n",
    "\n",
    "Wenn wir ein `String` statt ein `int` haben können wir keine Rechen Operationen durchführen. \n",
    "Wie Mittelwert, Median, Standardabweichung, Varianz, etc.\n",
    "\n",
    "- Daher ist es wichtig die *Datentypen* zu kennen und zu ändern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['metro'] = df['metro'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Code wirst du eine Statitische Zusammenfassung des Datensatzes erhalten.\n",
    "Nimm dir eigene Minuten Zeit dein Daten satz zu analysieren und die wichtigsten Informationen herauszufinden.\n",
    "\n",
    "- Hinterfrage deine Daten und versuche Zusammenhänge zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)\n",
    "\n",
    "\n",
    "# save output of the describtion as a text file\n",
    "with open('MLP_Output/out.txt', 'w') as f:\n",
    "    f.write(df.describe().round(2).to_string()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umgang mit NaN-Werten (Not a Number):\n",
    "---\n",
    "NaN Werte sind Daten die nicht richtig erhoben worden oder auch fehler enthalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim Umgang mit fehlenden Werten in der Spalte \"educ\" (Bildungsjahre) sollte eine besonders sorgfältige Vorgehensweise angewendet werden.\n",
    "\n",
    "**Frage: Kann man fehlende Werte in der Spalte \"educ\" sinnvoll ersetzen?**\n",
    "\n",
    "Antwort: *Ja, aber mit Vorsicht.* \n",
    "Die Anzahl der Bildungsjahre kann möglicherweise durch den `Durchschnitt`, `Median` oder `Modus` ersetzt werden, aber dies muss mit Bedacht erfolgen. Der Grund ist, dass Bildung ein stark individueller Faktor ist und eine pauschale Ersetzung (z.B. mit dem `Mittelwert`) die Daten verfälschen könnte.\n",
    "Wenn fehlende Werte in `\"educ\"` durch den Durchschnitt oder eine andere aggregierte Statistik ersetzt werden, kann dies dazu führen, dass wichtige individuelle Unterschiede verwischt werden. Das könnte letztlich das Modell in die Irre führen, da die Annahmen über die Bildungsjahre nicht korrekt widergespiegelt werden. Eine solche Verzerrung könnte die Ergebnisse von Modellen wie der Regressionsanalyse oder anderen maschinellen Lernverfahren erheblich beeinflussen und zu ungenauen Vorhersagen führen.\n",
    "\n",
    "Statt pauschaler Ersetzungen sollten im besten Fall Strategien wie:\n",
    "\n",
    "- Datenquellen ergänzen, um fehlende Werte zu rekonstruieren,\n",
    "- Imputation mit verwandten Variablen (z.B. Alter, Berufserfahrung), oder\n",
    "- Löschen betroffener Zeilen, wenn der Anteil fehlender Werte gering ist,\n",
    "in Betracht gezogen werden, um die Verzerrung minimal zu halten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entferne Zeilen mit fehlenden Werten (NaN)\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# Fülle NaN-Werte mit dem Durchschnitt jeder Spalte\n",
    "#df = df.fillna(df.mean())\n",
    "\n",
    "\n",
    "# Alternativ: Fülle NaN-Werte einer bestimmten Spalte (z.B. 'Wage') mit deren Durchschnitt\n",
    "df['wage'] = df['wage'].fillna(df['wage'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filterung der Daten\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Datenfilterung kannst du neue Einsichten für deine Daten erhalten.\n",
    "Diese können wiederum in einer neuen `Variable` eingespeichert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df`: Der DataFrame, der die ursprünglichen Daten enthält.\n",
    "\n",
    "- `df[\"wage\"] > 12.00`: Die Filterbedingung. Es wird überprüft, ob der Wert in der Spalte \"wage\" größer als 12.00 ist.\n",
    "\n",
    "- `df[df[\"wage\"] > 12.00]`: Das Ergebnis ist ein neuer DataFrame (df_filtered), der nur die Zeilen enthält, in denen der Wert in der Spalte \"wage\" größer als 12.00 ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df[\"wage\"] > 12]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Filterung mit mehreren Konditionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_educ = df[(df[\"wage\"] > 12)  & # Beachte das du nun deine gewünschte Spalten namen hinzufügen musst\n",
    "                      (df[\"educ\"] == 12) & \n",
    "                      (df[\"metro\"] == 0) &\n",
    "                      (df[\"exper\"] > 1)] \n",
    "df_filtered_educ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisierungen:\n",
    "\n",
    "Visualisierungen sind leicht zu erstellen und bieten oft wertvolle Einblicke in die Daten, die möglicherweise anders ausfallen, als zunächst erwartet.\n",
    "\n",
    "Sie sind besonders wichtig, da sie nicht nur helfen, die Ergebnisse des Regressionsmodells besser zu verstehen, sondern auch dazu beitragen können, die Vorhersagen anschaulich zu untermauern. Wie genau Visualisierungen die Aussagekraft der Modellierung unterstützen, werden wir nach der Durchführung und dem Testen der Regression näher betrachten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Vis\"):\n",
    "    print(\"Ordner Vis erstellt\")\n",
    "    os.makedirs(\"Vis\") \n",
    "elif os.path.exists(\"Vis\"):\n",
    "    print(\"Ordner Vis ist bereits vorhanden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramm\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot der Verteilung\n",
    "sns.histplot(data=df[\"wage\"], bins=30, color=\"lightblue\")\n",
    "plt.xlabel(\"Lohn\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.title(\"Histogramm des Lohns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Daten ohne NaN-Werte\n",
    "data_wage = df['wage']\n",
    "\n",
    "# Berechne die Perzentile (25., 50., 75.)\n",
    "q25_wage = np.percentile(data_wage, 25)\n",
    "q50_wage = np.percentile(data_wage, 50)  # Median\n",
    "q75_wage = np.percentile(data_wage, 75)\n",
    "\n",
    "# Plot der Verteilung\n",
    "sns.histplot(data_wage, bins=30, color=\"lightblue\")\n",
    "\n",
    "# Füge die vertikalen Linien für die Perzentile hinzu\n",
    "plt.axvline(x=q25_wage, color='red', linestyle='--', label='25. Perzentil')\n",
    "plt.axvline(x=q50_wage, color='green', linestyle='--', label='50. Perzentil (Median)')\n",
    "plt.axvline(x=q75_wage, color='blue', linestyle='--', label='75. Perzentil')\n",
    "\n",
    "# Plot-Details\n",
    "plt.legend()\n",
    "plt.xlabel(\"Lohn\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.title(\"Histogramm des Lohns\")\n",
    "plt.show()\n",
    "# plt.savefig(\"Vis/Title_\") # speicher die Visualisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korrelations Matrix\n",
    "---\n",
    "Folgenden Methoden sind möglich: `pearson, kendall, spearman`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(method = \"pearson\", numeric_only=True), annot=True) \n",
    "plt.title(\"Heatmap der Korrelationen\")\n",
    "# in \"method\" kann du folgenden Mehthoden aussuchen pearson, kendall, spearman\n",
    "\n",
    "\n",
    "# plt.savefig(\"Vis/Title_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"exper\", y=\"wage\", alpha=0.5) # alpha fügt transparenz hinzu\n",
    "plt.xlabel(\"Erfahrung\")\n",
    "plt.ylabel(\"Lohn\")\n",
    "plt.title(\"Scatterplot von Erfahrung und Lohn\")\n",
    "# plt.savefig(\"Vis/Title_\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balkendiagramm\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df, x=\"metro\", y=\"wage\")\n",
    "plt.xlabel(\"Metro\")\n",
    "plt.ylabel(\"Lohn\")\n",
    "plt.title(\"Metro und Lohn\")\n",
    "# plt.savefig(\"Vis/Title_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressions Analyse\n",
    "---\n",
    "Im folgenden erstellen wir nun eine Mutiple Lineare Regression\n",
    "\n",
    "#### Formel:\n",
    "`wage ~ educ + exper + metro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lege deine abhängige und unabhängige Variable fest\n",
    "\n",
    "- In der `Variable X` erstellen wir ein neues Dataframe nur mit den Spalten educ, exper, metro\n",
    "\n",
    "- In der `Variable Y` erstellen wir ein neues Dataframe nur mit den Spalte wage die wir demenstsprechend auch vorhersagen möchten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"educ\", \"exper\", \"metro\"]] \n",
    "y = df[\"wage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstelle deine Regression:\n",
    "Regressionen können auf viele wege erstellt werden wir arbeiten nun mit dem Package Statsmodels da diese viele Metriken uns wiedergeben\n",
    "\n",
    "1. Möglichkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "model_stats = sm.OLS(y, X)\n",
    "model = model_stats.fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "with open('MLP_Output/summary.txt', 'w') as fh:\n",
    "    fh.write(model.summary().as_text()) # Speicher dein Regressions Ergebnis in einer Text Datei in dem Odner Regression Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = model.params\n",
    "parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formel: y_hat = intercept + b1 * educ + b1 * exper + b1 * educ + b1 * metro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educ = 0\n",
    "exper = 0\n",
    "metro = 0\n",
    "\n",
    "y_hat = parameter[0] + parameter[1] * educ + parameter[2] * exper + parameter[3] + metro\n",
    "\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Möglicheit die mehr an R erinnert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols \n",
    "linear_model = ols('wage ~ educ + exper + metro', \n",
    "                   data=df).fit()\n",
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfidenz Intervalle:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 99% confidence intervals for the model's parameters\n",
    "conf_intervals = linear_model.conf_int(alpha=0.01)\n",
    "conf_intervals = conf_intervals.rename(columns={0: '0.5 %', 1: '99.5 %'})\n",
    "conf_intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersagen treffen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = linear_model.predict(df[[\"educ\",\"exper\",\"metro\"]])\n",
    "prediction[:5] # Die ersten 5 Vohersagen, um alle zu sehen entferne die [:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=prediction, y=df[\"wage\"])\n",
    "plt.title(\"Tatsächliche Werte vs Vohergesagten Werte\")\n",
    "plt.xlabel(\"Tatsächliche Werte\")\n",
    "plt.ylabel(\"Vohergesagten Werte\")\n",
    "plt.savefig(\"Vis/Title_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuale \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuale berechen\n",
    "\n",
    "1. Möglichkeit durch eine eingbaute Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = linear_model.resid\n",
    "residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Möglichkeit eigene berechnung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_model = df[\"wage\"] - prediction # tatsächliche Werte - Vorhersagen\n",
    "residuals_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSResiduals = (residuals**2).sum()\n",
    "\n",
    "SSTotal = ((df[\"wage\"] - df[\"wage\"].mean())**2).sum()\n",
    "\n",
    "# R-squared\n",
    "R_squared = 1 - (SSResiduals/SSTotal)\n",
    "print(\"R_squared:\", R_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen (Predictions)\n",
    "predictions = linear_model.fittedvalues\n",
    "\n",
    "# Scatterplot der Vorhersagen gegen Residualen\n",
    "sns.scatterplot(x=predictions, y=residuals, alpha = 0.5)\n",
    "plt.title(\"Vorhersagen vs Residualen\")\n",
    "plt.axhline(y = 0, color = 'r', linestyle = '--') # fügt eine rote horziontale Linie hinzu\n",
    "plt.xlabel(\"Vorhersagen\")\n",
    "plt.ylabel(\"Residualen\")\n",
    "plt.savefig(\"Vis/Title_Residuals_vs_Predictions.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear_model.fittedvalues.mean())\n",
    "print(linear_model.predict().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(x=prediction, y=residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_residuals = model.resid\n",
    "sns.histplot(model_residuals, kde=True, bins=25)\n",
    "plt.savefig(\"Vis/Title_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.qqplot(residuals, line=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of variance (Anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Daten vorbereiten\n",
    "#df['metro'] = df['metro'].astype('category')  # Falls \"metro\" eine binäre Kategorie ist\n",
    "\n",
    "# Lineares Modell erstellen (OLS = Ordinary Least Squares)\n",
    "model = smf.ols('wage ~ educ + exper + metro', data=df).fit()\n",
    "\n",
    "# ANOVA-Test durchführen\n",
    "anova_results = anova_lm(model)  # Typ 2 ANOVA\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Lineare Regression aufbauen\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data = df, x=\"educ\", y =\"wage\")\n",
    "plt.savefig(\"Vis/Title_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data = df, x=\"exper\", y =\"wage\", scatter_kws={'color': 'grey'}, line_kws={'color': 'red'})\n",
    "# plt.savefig(\"Vis/Title_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data = df, x=\"metro\", y =\"wage\", scatter_kws={'color': 'grey'}, line_kws={'color': 'red'})\n",
    "\n",
    "# plt.savefig(\"Vis/Title_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of variance (Anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Daten vorbereiten\n",
    "#df['metro'] = df['metro'].astype('category')  # Falls \"metro\" eine binäre Kategorie ist\n",
    "\n",
    "# Lineares Modell erstellen (OLS = Ordinary Least Squares)\n",
    "model = smf.ols('wage ~ educ + exper + metro', data=df).fit()\n",
    "\n",
    "# ANOVA-Test durchführen\n",
    "anova_results = anova_lm(model)  # Typ 2 ANOVA\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heteroskedasticity testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "from statsmodels.formula.api import ols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_lm, bp_lm_pvalue, bp_fvalue, bp_f_pvalue = sm.stats.diagnostic.het_breuschpagan(\n",
    "    linear_model.resid, linear_model.model.exog)\n",
    "\n",
    "\n",
    "print(f\"LM Statistic: {bp_lm}\")\n",
    "print(f\"LM p-value: {bp_lm_pvalue}\")\n",
    "print(f\"F Statistic: {bp_fvalue}\")\n",
    "print(f\"F p-value: {bp_f_pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = sm.OLS(y, X).fit(cov_type=\"HC1\")\n",
    "print(ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multikollinearität\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "# VIF Berechnung nur für die Variablen in X\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "\n",
    "# Berechne den VIF für jede unabhängige Variable\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial-Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_creamdf = pd.read_csv(\"Data/ice_cream_sales.csv\", sep=',')\n",
    "ice_creamdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = ice_creamdf[\"Temperature (°C)\"].values.reshape(-1,1)\n",
    "X_log = sm.add_constant(X_poly)\n",
    "y_poly = ice_creamdf[\"Ice Cream Sales (units)\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "xp = polynomial_features.fit_transform(X_poly)\n",
    "xp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poly = sm.OLS(y_poly, xp).fit()\n",
    "ypred_poly = model_poly.predict(xp) \n",
    "\n",
    "ypred_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poly.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_poly,y_poly)\n",
    "plt.plot(X_poly,ypred_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Log Model:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Beispiel-Daten\n",
    "data = {\n",
    "    'X': [1, 2, 3, 4, 5, 6],\n",
    "    'y': [1, 2, 4, 8, 16, 32]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Logarithmieren der Variablen\n",
    "df['log_X'] = np.log(df['X'])\n",
    "df['log_y'] = np.log(df['y'])\n",
    "\n",
    "# Hinzufügen einer Konstante für den Intercept\n",
    "X_log = sm.add_constant(df['log_X'])\n",
    "\n",
    "# Erstelle das log-log Modell\n",
    "model = sm.OLS(df['log_y'], X_log)\n",
    "results = model.fit()\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(results.summary())\n",
    "\n",
    "# Vorhersagen treffen\n",
    "y_pred_log = results.predict(X_log)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
