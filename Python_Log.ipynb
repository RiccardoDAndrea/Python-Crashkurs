{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Empirisches Projekt\n",
    "---\n",
    "### **Skript zu Daten Manipulation, Visulallisierung und zur Regressions Analyse**\n",
    "\n",
    "Dieses Sktipt soll euch helfen eine Datenanalyse sowie eine `Logistische Regression` aufzubauen.\n",
    "\n",
    "*-> Falls ihr fragen habt bitte sagt mir bescheid ich helfe gerne aus!*\n",
    "\n",
    "> E-Mail: riccardo.dandrea@live.de\n",
    "> Ihr könnte gerne eine Mail schreiben wo wir uns Per zoom treffen können, falls ihr schwierigkeiten habt bei der Programmierung:\n",
    "> BITTE schreibt in der MAIL:\n",
    "> - Was habt ihr vor ?\n",
    "> - Wo liegt das Problem mit Code und Fehlermeldung\n",
    "> - und wann ihr euch Per zoom treffen wollt Tag und Uhrzeit.\n",
    "\n",
    "Diese Information geben mir Zeit mich vorzubereiten auf das Problem\n",
    "\n",
    "Für die Datenanalyse kann als unterstützung der Leitfaden \"Leitfaden.ipynbn\" als unterstützung genutzt werden.\n",
    "Ab Punkt 2. wird erklärt wie Libaries installiert werden und wie die Daten eingelesen werden können. Sowie weitere Schritte zur Datenanalyse.\n",
    "\n",
    "\n",
    "**Bedenke das du deine Daten immer hinterfragen solltest!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Informationen zu den Daten findest du unter folgenden \n",
    "Link: https://www.kaggle.com/datasets/shubhamgupta012/titanic-dataset\n",
    "\n",
    "The dataset includes the following columns:\n",
    "\n",
    "- PassengerId: Unique identifier for each passenger.\n",
    "- Survived: Survival status of the passenger (0 = Not Survived, 1 = Survived).\n",
    "- Pclass: Passenger class (1 = First class, 2 = Second class, 3 = Third class).\n",
    "- Sex: Gender of the passenger.\n",
    "- Age: Age of the passenger.\n",
    "- SibSp: Number of siblings/spouses aboard the Titanic.\n",
    "- Parch: Number of parents/children aboard the Titanic.\n",
    "- Fare: Fare paid by the passenger.\n",
    "- Embarked: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab:\n",
    "---\n",
    "1. [Programmierung mit Google Colab link](https://colab.research.google.com/drive/1KXsA9WTFS9AxezEEaI3gYirv42b5-0rb#scrollTo=VJul2ijN-eHj)\n",
    "2. Klickt auf `Datei` -> Notebook öffnen -> Github \n",
    "3. und fügt folgenden Link ein https://github.com/RiccardoDAndrea/Python-Crashkurs \n",
    "4. Wählt die Datei Python_MLR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Github: \n",
    "Hier werdet ihr den Code finden sowie die Beispiel Daten:\n",
    "\n",
    "https://github.com/RiccardoDAndrea/Python-Crashkurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"Data\"):\n",
    "    print(\"Ordner Data erstellt\")\n",
    "    os.makedirs(\"Data\") \n",
    "elif os.path.exists(\"Data\"):\n",
    "    print(\"Ordner Data ist bereits vorhanden\")\n",
    "\n",
    "\n",
    "if not os.path.exists(\"LOG_Output\"):\n",
    "    print(\"Ordner LOG_Output erstellt\")\n",
    "    os.makedirs(\"LOG_Output\") \n",
    "elif os.path.exists(\"LOG_Output\"):\n",
    "    print(\"Ordner LOG_Output ist bereits vorhanden\")\n",
    "\n",
    "# Erstellt dir ein Ordner wo du deine Daten speichern kannst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier wird der Download für den Datensatz vorbereitet\n",
    "file_id = '1uujka4TJygnHSrai5rDmao8z9SeP_PsE'\n",
    "download_link = f\"https://drive.google.com/uc?id={file_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einen Datensatz mit Pandas laden\n",
    "df = pd.read_csv(download_link, sep = \",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Redundante Spalten zu entfern kannst du folgende Funktion nutzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(columns=[\"Spalte\"], inplace=True) #<- Füge hier deine Spalte ein die du entferenen willst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anpassung der Datentypen\n",
    "---\n",
    "Bevor Daten richtig Manipuliert werden können ist es von wichtigkeit die Datentypen anzupassen.\n",
    "Welche Datentypen es gibt kannst du im Detail im Leitfaden nachlesen unter Punkt 1.3.\n",
    "\n",
    "Folgende Datentypen gibt es:\n",
    "\n",
    "-> `\"string\"`\n",
    "\n",
    "-> `\"int\"`\n",
    "\n",
    "-> `\"float\"`\n",
    "\n",
    "-> `\"bool\"`\n",
    "\n",
    "-> `\"category\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entscheide nun im folgenden welcher Datentyp am besten wäre für  deine Daten:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Survived'] = df[\"Survived\"].astype(\"category\")\n",
    "# df['Age'] = df['Age'].astype(\"int\")\n",
    "# df['Name'] = df['Name'].astype(\"Dein_Datentyp\")\n",
    "# df['Sex'] = df['Sex'].astype(\"Dein_Datentyp\")\n",
    "# df['Ticket'] = df['Ticket'].astype(\"Dein_Datentyp\")\n",
    "# df['Cabin'] = df['Cabin'].astype(\"Dein_Datentyp\")\n",
    "# df['Embarked'] = df['Embarked'].astype(\"Dein_Datentyp\")\n",
    "\n",
    "print(df.info())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistische Zusammenfassung:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)\n",
    "\n",
    "with open('LOG_Output/out.txt', 'w') as f:\n",
    "    f.write(df.describe().round(2).to_string()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umgang mit NaN-Werten (Not a Number):\n",
    "---\n",
    "NaN Werte sind Daten die nicht richtig erhoben worden oder auch fehler enthalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fehlende Werte:**\n",
    "Der Umgang mit fehlenden Werten ist ein entscheidender Schritt bei der Datenvorbereitung und sollte für jede Spalte individuell betrachtet werden.\n",
    "\n",
    "Die zentrale Frage sollte immer lauten: **Kann ich die fehlenden Werte sinnvoll ersetzen?**\n",
    "\n",
    "Beispiel: Spalte `\"Age\"` (Alter)\n",
    "In diesem Fall stellt sich die Frage: Kann man fehlende Werte in der Spalte `\"Age\"` sinnvoll ersetzen?\n",
    "\n",
    "- Antwort: NEIN. Das Alter lässt sich nicht einfach durch den Median, den Modus, den Mittelwert oder den vorherigen Wert ersetzen. Ein solches Vorgehen könnte die Daten erheblich verfälschen, was letztlich dazu führen würde, dass das Modell ungenaue Vorhersagen trifft. Diese Art der Datenmanipulation würde dazu führen, dass das Modell auf falschen Annahmen basiert, was gravierende Auswirkungen auf die Regressionsanalyse und die Vorhersagegenauigkeit hätte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden sehen wir das Beispiel an unseren Datensatz und sehen\n",
    "- Age fehlen 177 Werte\n",
    "- Cabin fehlend 687 Werte\n",
    "- Embarked fehlen 2 Werte.\n",
    "\n",
    "Wie würdet ihr mit den fehlenden Werten umgehen begründet eure Entscheidung?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösche die Zeilen mit NaN values. ACHTUNG hier werden aus deinem Dataframe ALLE Na values entfernt\n",
    "df = df.dropna(subset=['Age'])\n",
    "#df = df.dropna()\n",
    "\n",
    "# Fülle die NaN values mit einem Wert deiner Wahl. ACHTUNG hier werden aus deinem Dataframe ALLE Na values ersetzt mit der eingefügten Zahl\n",
    "\n",
    "#df = df.fillna() # Ein Zahl, Formel oder auch ein Funktion kann eingeben. Sollte jedoch immer ein Zahl (int oder float) returnen\n",
    "\n",
    "# Fülle die NaN values mit dem Durchschnittswert der Spalte\n",
    "\n",
    "#df[\"wage\"]= df[\"wage\"].fillna(df[\"wage\"].mean()) # nur eine Spalte werden die Daten ersetzt\n",
    "#df = df.fillna(df.mean()) #<- mean(), mode(), median() / Alle Spalten werden ersetzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist immer wieder sinnvoll sich die Daten anzuschauen, um zu sehen ob die Daten richtig verarbeitet wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenfilterung\n",
    "---\n",
    "Mit der möglichkeit Daten zufiltern kannst du deine Daten so unterteilen. Um Strukturen oder auch Gruppen festzuleggen die du später\n",
    "genau untersuchen möchtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_dead = df[(df[\"Survived\"] == 0)] #<- ein Dataframe nur mit verstorben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_sur = df[(df[\"Survived\"] == 1)]  #<- ein Dataframe nur mit den Überlebenden\n",
    "df_filtered_sur.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df[\"Survived\"] == 1) &\n",
    "                     (df[\"Pclass\"] == 1)]\n",
    "\n",
    "df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "---\n",
    "Daten zu Visualisieren geben die neue und detalierte einsichten in deinen Daten daher ist es ratsam sich die Zeit zu nehmen und sich die Daten zu visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived', data=df)\n",
    "plt.title(\"How many people have Survived ?\")\n",
    "#plt.xlabel(\"Survial count plot\")\n",
    "#plt.legend(['First line', 'Second line'],loc=\"upper left\")\n",
    "\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived',hue='Sex',data=df)\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Survived',hue='Pclass',data=df)\n",
    "plt.title(\"Survival count plot\")\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Daten ohne NaN-Werte\n",
    "data_age = df['Age'].dropna()\n",
    "\n",
    "# Berechne die Perzentile (25., 50., 75.)\n",
    "q25_age = np.percentile(data_age, 25)\n",
    "q50_age = np.percentile(data_age, 50)  # Median\n",
    "q75_age = np.percentile(data_age, 75)\n",
    "\n",
    "# Erstelle den Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot der Verteilung\n",
    "sns.histplot(data_age, kde=True, bins=30, color=\"lightblue\")\n",
    "\n",
    "# Füge die vertikalen Linien für die Perzentile hinzu\n",
    "plt.axvline(x=q25_age, color='red', linestyle='--', label='25. Perzentil')\n",
    "plt.axvline(x=q50_age, color='green', linestyle='--', label='50. Perzentil (Median)')\n",
    "plt.axvline(x=q75_age, color='blue', linestyle='--', label='75. Perzentil')\n",
    "\n",
    "# Plot-Details\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Altersverteilung mit Perzentilen')\n",
    "plt.xlabel('Alter')\n",
    "plt.ylabel('Anzahl')\n",
    "\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistische Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da eine Logistische Regression ein berechnung mit nummerischen Werte sind müssen wir zu nächst Überlegen welche Spalten ein relevanten beitrag zu unserer Regression beitragen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Spalten Parch, Embarked, Name, SibSp, PassengerId verfolgen keine musster oder Gruppierung woraus Schlüsse geozgen werden können die ein Wert vollen beitrag zu einer Regression bei tragen kann daher entfernen wie diese.\n",
    "\n",
    "Für die beschreibung der Spalten schaut gerne nochmal am anfang des Skriptes nach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Ticket\",\"Parch\",\"Embarked\",\"Name\",\"SibSp\",\"PassengerId\",\"Cabin\",\"Fare\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um auch das Geschlecht in der Klassifikation zu berücksichtigen, müssen wir die Spalte von String auf Nummerische Werte umwandeln.\n",
    "Hierfür ersetzten wir `\"male\"` mit dem int 0 und `\"Female\"` mit dem int 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].replace(['male','female'], [0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eine Klassifikation durchzuführen müssen wir die anhängige Variable (y) in unseren Fall \"Survived\" von den unabhängigen Variablen (X) trennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Survived']\n",
    "X = df.drop(columns=[\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung der Logitischen Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 2: Initialisiere das Modell\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Schritt 3: Trainiere das Modell mit den Trainingsdaten\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`accuracy:` sagt aus wie gut das Modell indem er prozentual wiedergibt wie viel das Model richtig vorhergesagt hat\n",
    "\n",
    "\n",
    "`AUC (Area Under Curve):` gibt die Gesamtleistung des Modells an. \n",
    "\n",
    "Ein AUC-Wert von:\n",
    "\n",
    "- 1: Perfekte Trennung der Klassen.\n",
    "\n",
    "- 0.5: Das Modell unterscheidet nicht besser als zufällige Vorhersagen (Zufallstreffer).\n",
    "\n",
    "- <0.5: Das Modell ist schlechter als zufällig und könnte die Klassen vertauschen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_pred[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score:\", accuracy_score(y, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 / 714 * (357+207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(model.coef_, columns=X.columns)\n",
    "dataframe[\"Intercept\"] = model.intercept_\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 7: Cross-Validation (5-fach)\n",
    "cv_score = cross_val_score(model, X, y, cv=5).mean()\n",
    "print(\"Cross-Validation Score (Mean):\", cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 9: Erstelle die Konfusionsmatrix für Testdaten\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['Perished', 'Survived']).plot(cmap='Blues')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Sensitivität (TPR)` misst, wie gut positive Fälle erkannt werden.\n",
    "\n",
    "### `Spezifität (TNR)` misst, wie gut negative Fälle erkannt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrahiere die Werte aus der Konfusionsmatrix\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "# Berechne Sensitivität (TPR)\n",
    "sensitivity = TP / (TP + FN)\n",
    "print(\"Sensitivität (True Positive Rate):\", sensitivity)\n",
    "\n",
    "# Berechne Spezifität (TNR)\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"Spezifität (True Negative Rate):\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 10: Zeige den Classification Report für Testdaten an\n",
    "print(\"Classification Report:\\n\", classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 11: Berechne und zeige die ROC-Kurve auf den Testdaten\n",
    "RocCurveDisplay.from_estimator(model, X, y)\n",
    "plt.savefig('LOG_Output/ROC_Curve.png')\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 12: Berechne den AUC-ROC-Score auf Testdaten\n",
    "auc_roc_score = roc_auc_score(y, model.predict_proba(X)[:,1])\n",
    "\n",
    "print(\"AUC-ROC Score:\", auc_roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung eine Vohersage: \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Person 1:\n",
    "\n",
    "- ***22 Jahre alt, männlich, 3. Klasse***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Male = [[3,1,22]]\n",
    "print(model.predict(Male)[0])\n",
    "probability = model.predict_proba(Male)[0][1]\n",
    "print(f'Überlebens wahrscheinlichkeit: {probability:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Person 2:\n",
    "\n",
    "- ***44 Jahre alt, Weiblich, 1. Klasse***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Female = [[1,1,44]]\n",
    "print(model.predict(Female)[0])\n",
    "probability = model.predict_proba(Female)[0][1]\n",
    "print(f'Probability of survival: {probability:.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('Pclass == 1 & Sex == 1 & Age == 44')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Person 3:\n",
    "\n",
    "- ***66 Jahre alt, männlich, 1. Klasse***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('Pclass == 3 & Sex == 0 & Age == 23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Female = [[3,0,23]]\n",
    "print(model.predict(Female)[0])\n",
    "probability = model.predict_proba(Female)[0][1]\n",
    "print(f'Probability of survival: {probability:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 1: Konstante (Intercept) hinzufügen\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "# Schritt 2: Logit-Modell erstellen\n",
    "logit_model = sm.Logit(y, X_const)\n",
    "\n",
    "# Schritt 3: Modell anpassen\n",
    "results_logit = logit_model.fit()\n",
    "print(results_logit.summary())\n",
    "# Schritt 4: Vorhersagen treffen\n",
    "predictions_Logit = results_logit.predict(X_const)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahrscheinlichkeiten aus dem Modell\n",
    "thresholds = 0.5\n",
    "# Wahrscheinlichkeiten in binäre Vorhersagen umwandeln (Schwellenwert = 0.5)\n",
    "binary_predictions = [1 if p > thresholds else 0 for p in predictions_Logit]\n",
    "\n",
    "# Konfusionsmatrix berechnen\n",
    "cm_Logit = confusion_matrix(y, binary_predictions)\n",
    "ConfusionMatrixDisplay(cm_Logit, display_labels=['Perished', 'Survived']).plot(cmap='Blues')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahrscheinlichkeiten in binäre Vorhersagen umwandeln (Schwellenwert = 0.5)\n",
    "binary_predictions = [1 if p > 0.5 else 0 for p in predictions_Logit]\n",
    "\n",
    "# Klassifikationsbericht basierend auf den binären Vorhersagen\n",
    "print(classification_report(y, binary_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahrscheinlichkeiten für Klasse 1 (positive Klasse) vorhersagen\n",
    "y_logit = results_logit.predict(X_const)\n",
    "\n",
    "# Berechne die FPR (False Positive Rate), TPR (True Positive Rate) und die Schwellenwerte\n",
    "fpr, tpr, thresholds = roc_curve(y, y_logit)\n",
    "\n",
    "# Berechne den AUC-Score (Area Under the Curve)\n",
    "roc_auc = roc_auc_score(y, y_logit)\n",
    "\n",
    "# ROC-Kurve anzeigen\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Logit Model')\n",
    "roc_display.plot()\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vohersagen mit dem Logit Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Probit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstante hinzufügen\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "# Probit-Modell erstellen und anpassen\n",
    "Probit_model = sm.Probit(y, X_const)\n",
    "\n",
    "# Schritt 3: Modell anpassen\n",
    "results_probit = Probit_model.fit()\n",
    "print(results_probit.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 4: Vorhersagen treffen\n",
    "predictions_probit = results_probit.predict(X_const)\n",
    "\n",
    "# Wahrscheinlichkeiten aus dem Modell\n",
    "predictions_probit[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahrscheinlichkeiten in binäre Vorhersagen umwandeln (Schwellenwert = 0.5)\n",
    "binary_predictions_probit = [1 if p > 0.5 else 0 for p in predictions_probit]\n",
    "\n",
    "# Konfusionsmatrix berechnen\n",
    "cm_Probit = confusion_matrix(y, binary_predictions_probit)\n",
    "ConfusionMatrixDisplay(cm_Probit, display_labels=['Perished', 'Survived']).plot(cmap='Blues')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klassifikationsbericht basierend auf den binären Vorhersagen\n",
    "print(classification_report(y, binary_predictions_probit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne die FPR (False Positive Rate), TPR (True Positive Rate) und die Schwellenwerte\n",
    "fpr, tpr, thresholds = roc_curve(y, predictions_probit)\n",
    "\n",
    "# Berechne den AUC-Score (Area Under the Curve)\n",
    "roc_auc = roc_auc_score(y, predictions_probit)\n",
    "\n",
    "# ROC-Kurve anzeigen\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Logit Model')\n",
    "roc_display.plot()\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.savefig(\"LOG_Output/Title_\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Schritt 1: Erstelle eine Kreuztabelle\n",
    "# Annahme: df ist dein DataFrame mit den Variablen 'Survived' und 'Pclass'\n",
    "contingency_table = pd.crosstab(df['Survived'], df['Age'])\n",
    "\n",
    "# Schritt 2: Chi²-Test durchführen\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(f\"Chi²-Wert: {chi2}\")\n",
    "print(f\"p-Wert: {p}\")\n",
    "print(f\"Freiheitsgrade: {dof}\")\n",
    "print(\"Erwartete Häufigkeiten:\")\n",
    "print(expected)\n",
    "\n",
    "# Beurteilung des Ergebnisses\n",
    "if p < 0.05:\n",
    "    print(\"Das Ergebnis ist statistisch signifikant. Es gibt einen Zusammenhang zwischen den Variablen.\")\n",
    "else:\n",
    "    print(\"Das Ergebnis ist nicht statistisch signifikant. Es gibt keinen Zusammenhang zwischen den Variablen.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
