{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1. Empirisches Projekt\n",
    "---\n",
    "### **Übung zur Erstellung einer Mutiplen Linearen Regression**\n",
    "Dieses Sktipt soll euch helfen eine Datenanalyse sowie eine Simple oder eine Mutiple Regression aufzubauen.\n",
    "-> Falls ihr fragen habt bitte sagt mir bescheid ich helfe gerne aus!\n",
    "\n",
    "\n",
    "> E-Mail: riccardo.dandrea@live.de\n",
    "> Ihr könnte gerne eine Mail schreiben wo wir uns Per zoom treffen können, falls ihr schwierigkeiten habt bei der Programmierung:\n",
    "> BITTE schreibt in der MAIL:\n",
    "> - Was habt ihr vor ?\n",
    "> - Wo liegt das Problem mit Code und Fehlermeldung\n",
    "> - und wann ihr euch Per zoom treffen wollt Tag und Uhrzeit.\n",
    ">\n",
    "> Gerne bitte ich auch eine Sprechstunde neben den Vorlesungen wo wir uns einmal wöchentlich treffen und Ihr mir direkt Fragen stellt könnte.\n",
    "\n",
    "\n",
    "Für die Datenanalyse kann als unterstützung der Leitfaden \"Leitfaden.ipynbn\" als unterstützung genutzt werden.\n",
    "Ab Punkt 2. wird erklärt wie Libaries installiert werden und wie die Daten eingelesen werden können. Sowie weitere Schritte zur Datenanalyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Google Colab:\n",
    "---\n",
    "##### 1. [Python Programmierung mit Google Colab link](https://colab.research.google.com/drive/1_LOqSLE3ogQIeh5_ho03JoLbuJAGTnwF)\n",
    "\n",
    "<img src=\"Pictures_for_Explanation/1_Google_Colab_Starten.png\" alt=\"Bildbeschreibung\" width=\"600\"/>\n",
    "\n",
    "\n",
    "\n",
    "##### 2. Um ein Skript zu öffnen Navigiert auf Datei was oben Rechts vorzufinden ist und klickt \"Notebook öffnen\"\n",
    "\n",
    "<img src=\"Pictures_for_Explanation/2_Datei_Optionen_öffnen.png\" alt=\"Bildbeschreibung\" width=\"600\"/>\n",
    "\n",
    "##### 3. Danach geht ihr  auf Github und fügt folgenden Link hinzu https://github.com/RiccardoDAndrea/Python-Crashkurs\n",
    "\n",
    "<img src=\"Pictures_for_Explanation/3_Zuletzt_Geöffnet.png\" alt=\"Bildbeschreibung\" width=\"600\"/>\n",
    "\n",
    "##### 4. Nachdem Laden werdet ihr mehere Datein wie Skripte vorfinden.\n",
    "<img src=\"Pictures_for_Explanation/4_Github_URL_eingeben.png\" alt=\"Bildbeschreibung\" width=\"600\"/>\n",
    "\n",
    "##### 5. Für die Mutiple Lineare Regression wählt ihr Python_regression.ipynb und somit habt ihr erfolgreich das Skript zur bearbeitung eingeladen\n",
    "<img src=\"Pictures_for_Explanation/5_Python_MLR.png\" alt=\"Bildbeschreibung\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"Data\"):\n",
    "    print(\"Ordner Data erstellt\")\n",
    "    os.makedirs(\"Data\") \n",
    "elif os.path.exists(\"Data\"):\n",
    "    print(\"Ordner Data ist bereits vorhanden\")\n",
    "\n",
    "\n",
    "if not os.path.exists(\"MLR_Output\"):\n",
    "    print(\"Ordner Data erstellt\")\n",
    "    os.makedirs(\"MLR_Output\") \n",
    "elif os.path.exists(\"MLR_Output\"):\n",
    "    print(\"Ordner Data ist bereits vorhanden\")\n",
    "\n",
    "# Erstellt dir ein Ordner wo du deine Daten speichern kannst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 1\n",
    "---\n",
    "\n",
    "1. Importiert mit den richtigen abkürzung folgenden Packes:\n",
    "- pandas\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- numpy\n",
    "\n",
    "\n",
    "Ihr werdet wahrscheinlich eine kleine internet recherse betreiben müssen oder die anderen Skript euch angucken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols \n",
    "import sklearn as sk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 2. Daten einlesen\n",
    "--- \n",
    "Lese folgenden Link mit `Pandas` ein und speicher den Datensatz in der Variable `df`:\n",
    "\n",
    "- Link: https://raw.githubusercontent.com/plotly/datasets/refs/heads/master/auto-mpg.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=\"https://raw.githubusercontent.com/plotly/datasets/refs/heads/master/auto-mpg.csv\")\n",
    "\n",
    "\n",
    "df.rename(columns={\"model-year\":\"model_year\"}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **mpg:** Miles per Gallon (Meilen pro Gallone). Dies ist ein Maß für den Kraftstoffverbrauch eines Autos.\n",
    "\n",
    "- **cylinders:** Anzahl der Zylinder im Motor.\n",
    "\n",
    "- **displacement:** Hubraum des Motors. Der Hubraum ist ein Maß für das Arbeitsvolumen des Motors.\n",
    "\n",
    "- **horsepower:** Leistung des Motors in Pferdestärken. \n",
    "\n",
    "- **weight:** Gewicht des Autos. \n",
    "\n",
    "- **acceleration:** Beschleunigung des Autos. Die Beschleunigung gibt an, wie schnell ein Auto von 0 auf eine bestimmte Geschwindigkeit beschleunigt.\n",
    "\n",
    "- **model-year:** Baujahr des Autos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 3.\n",
    "---\n",
    "\n",
    "Gibt euch eine Statischte zusammenfassung der Daten wieder:\n",
    "\n",
    "count / mean / std / min / 25% / 50% / 75% / max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statischtische zusammenfassung:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 4. \n",
    "---\n",
    "\n",
    "Erstellt ein Code wo ihr für jede Spalte die NaN values betrachtet könnt\n",
    "\n",
    "Hierbei empfehle ich eine Internet recherse oder ihr schaut in die anderen Skripte rein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Überprüfe die NaN values:\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 5.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('horsepower.isnull()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Code seht ihr die Zeilen wo NaN Werte stehen.\n",
    "\n",
    "Entscheidet nun wie ihr am *SINNVOLLSTEN* eure Daten ersetzten wollt.\n",
    "*Seit bereit eure entscheidung zu begrüden.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ersetzte die NaN values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir bereits *Visualisierungen* besprochen haben werden wir diesen Teil abkürzen, indem wir ein `Pairplot` erstellen um ein groben überblick der Daten zu erhalten.\n",
    "\n",
    "Die Dokumentation für die Funktion `pairplot` findet ihr [hier](https://seaborn.pydata.org/generated/seaborn.pairplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 7.\n",
    "---\n",
    "\n",
    "7.1 Erstellt ein Korrelations Matrix\n",
    "\n",
    "7.2 Visualsiert bitte die Korrelation Matrix mit der Funktion `heatmap` aus seabron.\n",
    "\n",
    "7.3 Speichert nur die Visualsierte Korrelations Matrix in der Variable `Corr_Vis =` \n",
    "\n",
    "\n",
    "Als nützliche Hilfestellung könnt ihr folgende Internetseite nutzen: \n",
    "\n",
    "https://medium.com/@szabo.bibor/how-to-create-a-seaborn-correlation-heatmap-in-python-834c0686b88e\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufgabe 7.1\n",
    "\n",
    "df.corr()\n",
    "\n",
    "\n",
    "# Aufgabe 7.2 und 7.3\n",
    "Corr_Vis = sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutiple Lineare Regression:\n",
    "---\n",
    "\n",
    "Die folgende Regression werden wir aufbauen:\n",
    "\n",
    "-> *mpg = cylinders + displacement + horsepower + weight + acceleration + model-year*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 7.\n",
    "---\n",
    "\n",
    "Erstelle zwei Variabeln\n",
    "1. Die erste Variable `(X)` soll die abhängigen Spalten beinhalten\n",
    "2. Die zweite Variable `(y)` soll die unabhängige Variable enthalten\n",
    "\n",
    "*Wie Ihr dies erreicht ist euch überlassen, Ihr könnte gerne das Internet zu hilfe nutzen.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"mpg\"])\n",
    "y = df[\"mpg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden für die Mutiple aber auch Simple Lineare Regression das Package Statsmodels nutzen\n",
    "Die Dokumentation findet ihr hier: https://www.statsmodels.org/stable/regression.html\n",
    "\n",
    "In `Statsmodels` muss bevor die Regression durchgeführt wird ein Konstante hinzugefügt werden. \n",
    "\n",
    "Folgender Code führt dies aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um eine Regression aufzubauen haben wir zwei möglichkeiten:\n",
    "Die erste Möglichkeit ist durch nutzung der beiden Variabelen X und y die weiter oben definiert haben.\n",
    "\n",
    "### 1. Möglichkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = sm.OLS(y, X)\n",
    "model_stats = model_stats.fit()\n",
    "print(model_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Möglichkeit die mehr an R erinnert\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_R = ols(\"mpg ~ cylinders + displacement + horsepower + weight + acceleration + model_year\",\n",
    "                   data=df).fit()\n",
    "\n",
    "print(model_R.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngepasst Model mit Metriken die Signifikant und das Model verbessern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_R_adj = ols(\"mpg ~ weight + model_year\",\n",
    "                   data=df).fit()\n",
    "\n",
    "\n",
    "X = df[[\"weight\",\"model_year\"]]\n",
    "X = sm.add_constant(X)\n",
    "print(model_R_adj.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Evaluierung des Models:\n",
    "---\n",
    "#### *8.1 Welche Metriken sind für euch Relevant und was sagen Sie aus ?*\n",
    "*Hier habt ihr Platz um kurz und prägnet die wichtigsten Metriken auszuwerten und eure Gedanken aufzuschreiben*\n",
    "\n",
    "Metriken:\n",
    "\n",
    "\n",
    "\n",
    "#### *8.2 Beantwortet bitte folgenden Fragen:*\n",
    "\n",
    "- *was stellt der Intercept dar?*\n",
    "- *was sagen die Slopes aus ?*\n",
    "- *und wie beeinflusst das die Ziel Variable \"mpg\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durch die Funktion `model_R.params` können wir uns alle Koeffizienten sowie den Intercept in einer neuen Variable abspeichern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_R_adj.params)\n",
    "print(\"Anzahl an Werte zu extrahieren: \", len(model_R_adj.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Koeffizienten zu extrahieren nutzen wir folgenden Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Intercept = model_R_adj.params[0]\n",
    "weight_slope = model_R_adj.params[1]\n",
    "model_year_slope = model_R_adj.params[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressionsformel als String formatieren\n",
    "formula = f'mpg = {Intercept:.3f} + {weight_slope:.3f} * weight + {model_year_slope:.3f} * model_year'\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.iloc[0][2])\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_calc = Intercept + weight_slope * X.iloc[0][1] + model_year_slope * X.iloc[0][2] \n",
    "print(\"Die erste Vorhersage ist:\", formula_calc.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vohersagen treffen\n",
    "---\n",
    "\n",
    "Die vorhersage wird getroffen durch die Zelle davor aufgestellen Berechnung.\n",
    "\n",
    "**mpg = -14.583 + -0.0067 * weight + 0.7547 * model_year**\n",
    "\n",
    "Mit dieser Berechnungen wird in der Funktion predict(X) die werte in die Formel eingeben um Vorhersagen zu treffen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_R_adj.predict(X)\n",
    "\n",
    "# Die ersten 5 Vohersagen, um alle zu sehen entferne die [:5]\n",
    "prediction.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot erstellen \n",
    "plt.figure(figsize=(17, 6))\n",
    "sns.regplot(x=prediction, y=y)  # s=80 macht die Punkte größer\n",
    "\n",
    "# Die Regressionsformel in die Grafik einfügen\n",
    "plt.text(x=min(prediction), y=max(y), s=formula, fontsize=12, color='darkgreen')\n",
    "\n",
    "# Plot-Titel und Achsenbeschriftungen\n",
    "plt.title(\"Tatsächliche Werte vs Vorhergesagte Werte\", fontsize=16)\n",
    "plt.xlabel(\"Tatsächliche Werte\", fontsize=14)\n",
    "plt.ylabel(\"Vorhergesagte Werte\", fontsize=14)\n",
    "\n",
    "# Plot anzeigen und speichern\n",
    "plt.savefig(\"MLR_Output/Title_Actual_vs_Predicted_with_formula.png\", dpi=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X[\"weight\"], y=y, alpha=0.5)\n",
    "\n",
    "# Regressionslinie hinzufügen\n",
    "sns.lineplot(x=df[\"weight\"], y=prediction, color='red')\n",
    "\n",
    "plt.title(\"Tatsächliche Werte vs Vorhergesagte Werte (mit Regressionslinie)\")\n",
    "plt.xlabel(\"Gewicht (weight)\")\n",
    "plt.ylabel(\"Miles per Gallon (mpg)\")\n",
    "\n",
    "plt.savefig(\"MLR_Output/Tatsächliche Werte vs Vorhergesagte Werte.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuale berechnen\n",
    "---\n",
    "\n",
    "Resiudale sind die tatsächlichen Werte abzgl. die vorhersage Werte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 9. \n",
    "\n",
    "Berechnet die Residuale eingenständig:\n",
    "Nutz dafür Rechen Operatoren speichert die Ergebnis in der Variabel `resi =`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resiudale eingentständig berechnen\n",
    "\n",
    "resi = y - prediction\n",
    "\n",
    "resi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model_R_adj.resid\n",
    "residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 10.\n",
    "\n",
    "Visuallisiere die Residuale:\n",
    "\n",
    "1. Erstelle ein Scatterplot wo du die Vorhersage werte und die Residuale darstellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot der Vorhersagen gegen Residualen\n",
    "sns.scatterplot(y=residuals, x=prediction)\n",
    "\n",
    "plt.title(\"Vorhersagen vs Residualen\")\n",
    "plt.axhline(y = 0, color = 'r', linestyle = '--') # fügt eine rote horziontale Linie hinzu\n",
    "plt.xlabel(\"Vorhersagen\")\n",
    "plt.ylabel(\"Residualen\")\n",
    "\n",
    "\n",
    "plt.savefig(\"MLR_Output/Title_Residuals_vs_Predictions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstelle ein Histogramm mit den Resiudalen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=residuals, bins=15)\n",
    "plt.title(\"Histogramm der Residualen\")\n",
    "plt.xlabel(\"Residualen\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "\n",
    "\n",
    "plt.savefig(\"MLR_Output/Title_\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 11.\n",
    "Interpretieren den Histogramm und nimm stellung zu der Verteilung der Resiudale ? \n",
    "\n",
    "\n",
    "Stellungsnahme: Hier rein schreiben\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.qqplot(residuals, line='r')  # 'r' fügt die Referenzlinie hinzu\n",
    "plt.title(\"Q-Q Plot der Residuen\")\n",
    "plt.savefig(\"MLR_Output/Title_\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multikollinearität\n",
    "---\n",
    "\n",
    "\n",
    "*Der Variance Inflation Factor (VIF)* ist ein Maß dafür, wie stark die Varianz einer geschätzten Regressionskoeffizienten erhöht wird, wenn mehrere unabhängige Variablen in einem Regressionsmodell verwendet werden. Ein hoher VIF-Wert deutet darauf hin, dass die betreffende Variable stark mit anderen unabhängigen Variablen korreliert ist, was auf ein Problem der Multikollinearität hinweisen kann.\n",
    "\n",
    "\n",
    "VIF-Werte:\n",
    "- VIF < 5: Geringe Multikollinearität. Es besteht kein ernsthaftes Problem.\n",
    "- 5 ≤ VIF < 10: Moderate Multikollinearität, die möglicherweise problematisch ist.\n",
    "- VIF ≥ 10: Hohe Multikollinearität, die sehr problematisch ist und die Genauigkeit der Schätzung beeinträchtigen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# VIF Berechnung nur für die Variablen in X\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "\n",
    "# Berechne den VIF für jede unabhängige Variable\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "vif_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Code können wir nutzen um den VIF zu untermauern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hier eure Vermutgen reinschreiben und Schreibe die passende bereits definierte Variable dafür \n",
    "\n",
    "Corr_Vis = sns.heatmap(X[[\"weight\",\"model_year\"]].corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=X[\"weight\"], y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of variance (Anova)\n",
    "---\n",
    "\n",
    "Die ANOVA (Analysis of Variance) ist eine statistische Methode, die verwendet wird, um zu testen, ob es signifikante Unterschiede zwischen den Mittelwerten von drei oder mehr Gruppen gibt. Im Kontext einer linearen Regression (wie mit der Funktion anova_lm() von statsmodels) hilft sie uns zu verstehen, wie gut das Modell die Varianz in der abhängigen Variable erklärt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# ANOVA-Test durchführen\n",
    "anova_results = anova_lm(model_R_adj) \n",
    "anova_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgende Code zielt darauf ab, die ANOVA-Tabelle zusammenzufassen und die Ergebnisse der statistischen Analyse in einer strukturierten Form darzustellen. Dies umfasst die Berechnung von Freiheitsgraden, Summe der Quadrate, Mittelwert der Quadrate, F-Statistik und p-Werten, um signifikante Unterschiede zwischen den Gruppen zu identifizieren und die Variabilität in den Daten zu analysieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = anova_results[\"df\"][0:2].sum()\n",
    "SS = anova_results[\"sum_sq\"][0:2].sum().round(4)\n",
    "MS = anova_results[\"mean_sq\"][0:2].sum().round(4) / DF       # DF = 2\n",
    "F_statistic = anova_results[\"F\"][0:2].sum().round(4) / DF    # DF = 2\n",
    "p_value = anova_results[\"PR(>F)\"][0:2].sum().round(4)\n",
    "\n",
    "# Erstellen eines DataFrames\n",
    "results_df = pd.DataFrame({\n",
    "    \"DF\": [DF],\n",
    "    \"SS\": [SS],\n",
    "    \"MS\": [MS],\n",
    "    \"F_statistic\": [F_statistic],\n",
    "    \"p_value\": [p_value]},\n",
    "    index=[\"Regression\"])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals behalten\n",
    "residuals_anova = anova_results.iloc[2:3]\n",
    "residuals_anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen eines DataFrames\n",
    "df_resi = float(residuals_anova[\"df\"][0:1].values)\n",
    "sum_sq_resi = float(residuals_anova[\"sum_sq\"][0:1].values)\n",
    "mean_sq_resi = float(residuals_anova[\"mean_sq\"][0:1].values)\n",
    "\n",
    "# Erstellen eines DataFrames\n",
    "residuals_anova_df = pd.DataFrame({\n",
    "    \"DF\": [df_resi],\n",
    "    \"SS\": [sum_sq_resi],\n",
    "    \"MS\": [mean_sq_resi]},\n",
    "    index=[\"Residuals\"])\n",
    "df_anova = pd.concat([results_df,residuals_anova_df] )\n",
    "df_anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Regression_DF = df_anova[\"DF\"][0:2].sum()\n",
    "Total_residuals_SS = df_anova[\"SS\"][0:2].sum()\n",
    "\n",
    "total = pd.DataFrame({\n",
    "    \"DF\": [Total_Regression_DF],\n",
    "    \"SS\": [Total_residuals_SS],\n",
    "}, index=[\"Total\"])\n",
    "total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Bilden von Summen in bestimmten Spalten (wie SS) und das Auslassen in anderen (wie DF oder spezifische Statistiken) basiert auf der mathematischen und statistischen Logik hinter der ANOVA-Analyse. Es hilft, die wichtigsten Informationen über die Variation in den Daten klar und präzise zu präsentieren, ohne die Interpretierbarkeit oder Genauigkeit der Ergebnisse zu beeinträchtigen.\n",
    "\n",
    "\n",
    "### Finale Tabelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anova = pd.concat([df_anova,total])\n",
    "df_anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *df:* Wie viele Freiheitsgrade (unabhängige Informationen) für jede Variable vorhanden sind.\n",
    "\n",
    "- *sum_sq:* Die Gesamtmenge der durch die Variable erklärten Variabilität (höher ist besser).\n",
    "\n",
    "- *mean_sq:* Die pro Freiheitsgrad erklärte Variabilität (höher ist besser).\n",
    "\n",
    "- *F:* Gibt die Signifikanz des Einflusses der Variablen an (höher bedeutet ein signifikanterer Einfluss).\n",
    "\n",
    "- *PR(>F):* Der p-Wert, der die statistische Signifikanz testet (kleiner p-Wert bedeutet signifikanter Einfluss).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homoskedastizität oder Heteroskedastizität ?\n",
    "---\n",
    "\n",
    "\n",
    "<img src=\"Pictures_for_Explanation/heteroskedastizität.jpg\" alt=\"heteroskedastizität\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durchführung eines Breusch-Pagan-Test:\n",
    "---\n",
    "\n",
    "Der Breusch-Pagan-Test prüft die Nullhypothese von Homoskedastizität. Ein geringer p-Wert verwirft diese und nimmt die Alternativhypothese von Heteroskedastizität an.\n",
    "\n",
    "\n",
    "**Nullhypothese (H0):** Die Varianz der Residuen ist konstant (Homoskedastizität).\n",
    "\n",
    "**Alternativhypothese (H1):** Die Varianz der Residuen ist nicht konstant (Heteroskedastizität), wobei die Varianz möglicherweise eine Funktion der unabhängigen Variablen ist.\n",
    "\n",
    "Wenn der p-Wert klein ist (typischerweise < 0.05), lehnen wir die Nullhypothese der Homoskedastizität ab und schließen auf das Vorhandensein von Heteroskedastizität\n",
    "Ein größerer p-Wert (> 0.05) bedeutet, dass wir nicht genügend Beweise haben, um die Nullhypothese der Homoskedastizität abzulehnen\n",
    "\n",
    "*Unsere Daten Analyse:*\n",
    "In der Regel wird ein Wert < 10 als Heteroskedastizität angesehen\n",
    "\n",
    "In unseren fall haben wir Heteroskedastizität!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "bp_test = het_breuschpagan(resid=residuals, exog_het=X)\n",
    "\n",
    "print(\"LM-Statistik (Lagrange-Multiplier-Wert)\", bp_test[0].round(4))\n",
    "print(\"pvalue\", bp_test[1].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "White-Test:\n",
    "---\n",
    "Definition: Die LM-Statistik des White-Tests prüft, ob die Varianz der Residuen konstant ist (Homoskedastizität) oder ob sie abhängig von den unabhängigen Variablen variiert (Heteroskedastizität). Dabei berücksichtigt der White-Test zusätzlich auch nicht-lineare Beziehungen und Wechselwirkungen zwischen den unabhängigen Variablen.\n",
    "\n",
    "Interpretation: \n",
    "- Eine höhere LM-Statistik zeigt eine größere Wahrscheinlichkeit an, dass Heteroskedastizität vorliegt.\n",
    "- P-Value geringer P wert deutet auf Heteroskedastizität\n",
    "\n",
    "\n",
    "- **Nullhypothese (H0):** Es liegt keine Heteroskedastizität vor (Homoskedastizität).\n",
    "\n",
    "- **Alternativhypothese (H1):** Es liegt Heteroskedastizität vor, und die Varianz der Residuen könnte nicht nur von den unabhängigen Variablen abhängen, sondern auch von ihren quadrierten Werten und Kreuzprodukten.\n",
    "\n",
    "-> Generell wird ein LM-Wert von 10 oder mehr als signifikante *Heteroskedastizität* angesehen. In usneren Fall ist der Wert von 24.2386 hoch, was auf für Heteroskedastizität hinweist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durchführung eines White test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "wtest = het_white(resid=residuals, exog = X)\n",
    "print(\"lm\", wtest[0].round(4), \"lm_pvalue\", wtest[1].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vergleich mit dem Breusch-Pagan-Test:**\n",
    "Breusch-Pagan-Test: Testet nur auf lineare Abhängigkeiten zwischen den Residuen und den unabhängigen Variablen.\n",
    "\n",
    "\n",
    "**White-Test:** Erweitert den Test, indem er auch nicht-lineare Effekte (wie quadratische oder interaktive) zwischen den unabhängigen Variablen prüft. Dadurch ist der White-Test allgemeiner und kann auch komplexere Formen von Heteroskedastizität erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Breusch-Pagan und White*\n",
    "\n",
    "- Beide Tests (Breusch-Pagan und White) zeigen signifikante Hinweise auf Heteroskedastizität im Regressionsmodell. Das bedeutet, dass die Varianz der Residuen nicht konstant ist, was gegen eine der grundlegenden Annahmen der linearen Regression spricht. \n",
    "\n",
    "- Dies könnte die Schätzungen und die Validität der Hypothesentests im Modell beeinträchtigen. \n",
    "\n",
    "- Mögliche Lösungen wären das Transformieren der abhängigen Variablen oder die Verwendung robuster Standardfehler, um die Auswirkungen der Heteroskedastizität zu berücksichtigen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infall der *Heteroskedastizität* können wir in der Funktion `.fit()` den parameter mitgeben \n",
    "\n",
    "- `cov_type = 'nonrobust', 'fixed scale', 'HC0', 'HC1', 'HC2', 'HC3', 'HAC', 'hac-panel', 'hac-groupsum', 'cluster'` \n",
    "\n",
    "um unteranderem gegen Heteroskedastizität die werte anzupassen können wir die Parameter anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_R_adj_H1 = ols(\"mpg ~ weight + model_year\",\n",
    "                   data=df).fit(cov_type=\"HC1\")\n",
    "\n",
    "print(model_R_adj_H1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
